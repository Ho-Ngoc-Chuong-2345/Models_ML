# -*- coding: utf-8 -*-
"""Main_Train_XGBoost.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dbJ0fulZMiRBrb2BP7_nmngAmv-M7ygV

## 1. Import Library
"""

import pandas as pd
import numpy as np
import gdown
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import OneHotEncoder, MinMaxScaler
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.metrics import (
    classification_report, roc_auc_score, confusion_matrix,
    accuracy_score, precision_score, recall_score, f1_score
)
from xgboost import XGBClassifier
import warnings
warnings.filterwarnings("ignore")

"""## 2. Load Data"""

file_id = "1UJXIe6ioRQDN59Wi_2jtSx0daLRz21bz"
url = f"https://drive.google.com/uc?id={file_id}"
output = "Loan_Default_ModelReady.csv"

gdown.download(url, output, quiet=False)

data = pd.read_csv(output)
print("Dữ liệu sau preprocessing:", data.shape)
print(data.head())

"""## 3. EDA"""

print("\nThông tin tổng quát:")
print(data.info())
print("\nThống kê mô tả:")
print(data.describe().T)

plt.figure(figsize=(4,4))
sns.countplot(x='Status', data=data, palette='coolwarm')
plt.title("Tỉ lệ nhãn (Default vs Non-default)")
plt.show()

target_rate = data['Status'].value_counts(normalize=True)
print("\nTỉ lệ nhãn:\n", target_rate)

plt.figure(figsize=(10,6))
corr = data.select_dtypes(include=['int64', 'float64']).corr()
sns.heatmap(corr, cmap='coolwarm', annot=False)
plt.title("Ma trận tương quan giữa các biến số")
plt.show()

"""## 4. Split X and Y (Status)"""

X = data.drop('Status', axis=1)
y = data['Status']

X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, stratify=y, random_state=42
)

print(f"Train size: {X_train.shape}, Test size: {X_test.shape}")

"""## 5. Pipeline"""

cat_cols = [c for c in X_train.columns if X_train[c].dtype == 'object']
num_cols = [c for c in X_train.columns if X_train[c].dtype != 'object']

ct = ColumnTransformer(
    transformers=[
        ('encoder', OneHotEncoder(handle_unknown='ignore', sparse_output=False), cat_cols),
        ('scaler', MinMaxScaler(), num_cols)
    ],
    remainder='drop'
)

model = Pipeline(steps=[
    ('preprocessor', ct),
    ('classifier', XGBClassifier(
        n_estimators=250,
        learning_rate=0.1,
        max_depth=6,
        subsample=0.8,
        colsample_bytree=0.8,
        random_state=42,
        use_label_encoder=False,
        eval_metric='logloss',
        n_jobs=-1
    ))
])

"""## 6. Train Model"""

model.fit(X_train, y_train)

"""## 7. Metrics and Confusion Matrix"""

y_pred = model.predict(X_test)
y_prob = model.predict_proba(X_test)[:, 1]

acc = round(accuracy_score(y_test, y_pred), 4)
auc = round(roc_auc_score(y_test, y_prob), 4)
prec = round(precision_score(y_test, y_pred), 4)
rec = round(recall_score(y_test, y_pred), 4)
f1 = round(f1_score(y_test, y_pred), 4)

print("\nKẾT QUẢ ĐÁNH GIÁ")
print(f"Accuracy : {acc}")
print(f"ROC AUC  : {auc}")
print(f"Precision: {prec}")
print(f"Recall   : {rec}")
print(f"F1-score : {f1}")

print("\nClassification Report:")
print(classification_report(y_test, y_pred, digits=4))

cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(5,4))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=['Pred 0','Pred 1'], yticklabels=['Actual 0','Actual 1'])
plt.title("Confusion Matrix - XGBoost")
plt.show()